{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SDC11_actividad2_Badillo_Casanova.ipynb","provenance":[],"authorship_tag":"ABX9TyOTGyb7/CZHEGuocipFRlKN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"5jXN9S-IepeP"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2 as cv\n","import time"],"execution_count":1,"outputs":[]},{"source":["# Actividad 2. Señales de altos, autos y personas en un video"],"cell_type":"markdown","metadata":{"id":"FFwAcr6-ev8o"}},{"source":["______________________________\n","El primer paso a realizar, posterior a importar las librerías que se utilizarán, es el de importar los datos de Haar Cascade para detectar los objetos dentro del video. Haar cascade son patrones entrenados, estos están basados en imágenes positivas y negativas, las imágenes positivas son en las que se encuentra nuestro objeto a detectar mientras que las negativas son en las que no se encuentra nuestro objeto, estas son usadas de tal forma que nuestra máquina sepa que es lo que tiene que detectar y qué es lo que no para que de esta forma se pueda crear una _base de datos_. Entonces, los archivos **xml** usados acontinuación nos ayudarán a detectar **altos, autos y peatones** en nuestro video de manera que los usamos a modo de _función_ para aplicar posteriormente. \n","La librería usada para poder importar nuestros datos de detección es OpenCV, la cual está orientada a la visión computacional, la cual es multiplataforma (lo que quiere decir que puede ser utilizada en diversos lenguajes de programación, tales como C++, JavaScript, Java, etc. además de Python) e igualmente es de libre acceso.\n","\n","______________________________\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"llUtDh7YewOY"},"source":["#importando datos haar cascade\n","stop_cascade = cv.CascadeClassifier('datos/Stopsign_HAAR_19Stages.xml')\n","car_cascade = cv.CascadeClassifier('datos/cars.xml')\n","peaton_cascade = cv.CascadeClassifier('datos/haarcascade_fullbody.xml')\n"],"execution_count":2,"outputs":[]},{"source":["___________________________\n","A continuación se define la función que se aplicará en el video para la detección de nuestros objetos de interés, empezamos por definir los objetos detectados como _variables_ dentro de nuestra función ya que esto nos permitirá detectar cada objeto como uno diferente, separarlos como grupo según sus características que ya esteblecimos anteriormente a través de los archivos _xml_, para ello se usó **detectMultiScale** que es parte de la librería OpenCV y que nos ayuda a encontrar objetos en cada imagen arrojada por el video, para eso utiliza algunos parámetros, en este caso usamos \"gray\" ya que la escala de grises es la que permite la detección y el tamaño mínimo y máximo que son el 1 y el 5 respectivamente.\n","Posteriormente establecemos _coordenadas_ para cada una de nuestras variables a graficar, al igual que anteriormente lo hacemos con ayuda de la librería OpenCV, con lo cual podemos definir el tamaño, color e incluso la fuente usada para indicar a nuestro objeto detectado.\n","Finalmente guardamos estas _detecciones_ en unas variables para mostrarlas posteriormente en el video.\n","___________________________"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#definiendo funcion de deteccion\n","def video_detect(gray, frame):\n","    \n","    altos = stop_cascade.detectMultiScale(gray, 1, 5)\n","    autos = car_cascade.detectMultiScale(gray, 1, 5)\n","    peaton = peaton_cascade.detectMultiScale(gray, 1, 5)\n","\n","    for (x, y, w, h) in autos:\n","\n","        cv.rectangle(frame, (x, y), (x + w, y + h), (213,152,221), 2)\n","        cv.putText(frame, 'Carro', (x, y), 6, 0.8, (213,152,221), 2)\n","\n","        for (x, y, w, h) in altos:\n","\n","             cv.rectangle(frame, (x, y), (x + w, y + h), (76,163,221), 2)\n","             cv.putText(frame, 'Alto', (x, y), 6, 0.8, (76,163,221), 2)\n","\n","             for (x, y, w, h) in peaton:\n","\n","                 cv.rectangle(frame, (x, y), (x + w, y + h), (13,236,175), 2)\n","                 cv.putText(frame, 'Peaton', (x, y), 6, 0.8, (13,236,175), 2)\n","\n","\n","        fr_gray = gray[y:y + h, x:x + w]\n","        fr_color = frame[y:y + h, x:x + w]\n","        \n","    return frame"]},{"source":["_____________________________\n","Finalmente, mostramos el video. El primer paso para esto es importar el video y esto se hace a través de OpenCV con __VideoCapture__ el cual permitirá guardar el video en nuestra variable para ser analizado. De manera que definimos otra función para que mientras el video sea reproducido se detectarán los objetos frame a frame y se dibujarán los rectángulos y nombres como fue definido en nuestra función anterior; finalmente, establecemos que el video se cerrará con \"q\" y le "],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["video = cv.VideoCapture('videos/altos_peatones_automoviles.mp4')\n","\n","while(video.isOpened()):\n","\n","    ret, frame = video.read()\n","\n","    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n","\n","    video_canvas = video_detect(gray, frame)\n","    \n","    cv.imshow('video con rectangulos', video_canvas)\n","    if cv.waitKey(1) & 0xFF == ord('q'):\n","        time.sleep(3)\n","        break\n","\n","video.release()\n","cv.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}